{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Méthode de back-translation"
      ],
      "metadata": {
        "id": "mSkDcd9BVayC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install & Packages"
      ],
      "metadata": {
        "id": "obrEVGhmaLzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers\n",
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIdrzhyqS7nV",
        "outputId": "b8135bbb-3a6e-4a0c-fd70-878ab391fc61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.0 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.14.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (3.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
            "Collecting protobuf<=3.20.2\n",
            "  Downloading protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n",
            "Installing collected packages: sentencepiece, protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.2 sentencepiece-0.1.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Désactiver les messages d'avertissement\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "K2Nskn7VaQZJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rétrotraduction sur un texte"
      ],
      "metadata": {
        "id": "tbtkPdlDbKtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier si CUDA est disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\"\"\"\n",
        "  Cette fonction prend une chaîne de caractères en entrée et retourne une traduction rétrograde (back-translation) du texte en utilisant deux modèles de traduction automatique de Hugging Face. Le texte d'entrée est d'abord traduit du français vers l'anglais, puis de l'anglais vers le français.\n",
        "\n",
        "  Input :\n",
        "    text : str - Le texte à traduire\n",
        "    src_lang : str - (facultatif) La langue source du texte (français par défaut)\n",
        "    tgt_lang : str - (facultatif) La langue cible pour la traduction (anglais par défaut)\n",
        "\n",
        "  Output :\n",
        "    back_translated_text : str - La traduction rétrograde du texte en entrée\n",
        "\"\"\"\n",
        "def back_translation(text, src_lang=\"fr\", tgt_lang=\"en\"):\n",
        "    # Charger les tokenizers et les modèles\n",
        "    tokenizer_fr_to_en = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "    model_fr_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\").to(device)\n",
        "    \n",
        "    tokenizer_en_to_fr = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "    model_en_to_fr = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\").to(device)\n",
        "\n",
        "    # On découpe le texte par phrase\n",
        "    sentences = text.split('. ')\n",
        "    translated_chunks = []\n",
        "    for chunk in tqdm(sentences, desc=\"Translating sentences\"):\n",
        "        # Traduire du français vers l'anglais\n",
        "        inputs_fr_to_en = tokenizer_fr_to_en(chunk, return_tensors=\"pt\").to(device)\n",
        "        outputs_fr_to_en = model_fr_to_en.generate(**inputs_fr_to_en)\n",
        "        translated_text_en = tokenizer_fr_to_en.decode(outputs_fr_to_en[0], skip_special_tokens=True)\n",
        "\n",
        "        # Traduire de l'anglais vers le français\n",
        "        inputs_en_to_fr = tokenizer_en_to_fr(translated_text_en, return_tensors=\"pt\").to(device)\n",
        "        outputs_en_to_fr = model_en_to_fr.generate(**inputs_en_to_fr)\n",
        "        back_translated_text_fr = tokenizer_en_to_fr.decode(outputs_en_to_fr[0], skip_special_tokens=True)\n",
        "\n",
        "        translated_chunks.append(back_translated_text_fr)\n",
        "\n",
        "    back_translated_text = \" \".join(translated_chunks)\n",
        "\n",
        "    return back_translated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "QWGJ9SExccGH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple d'utilisation\n",
        "text = \"Les travaux que nous avons engagés ont impliqué la participation de développeurs, d’un modélisateur 3D et multimédia mais aussi d’un ingénieur recherche et développement, révélant de ce fait le caractère R&D de notre projet. Notre participation en 2021 à des activités de veille technologique comme des congrès ou des salons confortent également cette position.\"\n",
        "back_translated_text = back_translation(text)\n",
        "print(\"\\nTexte d'origine:\", text)\n",
        "print(\"Texte traduit en aller-retour:\", back_translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-EPhW6PVnns",
        "outputId": "c8065f18-70c6-4321-e8b0-dba77658203b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating sentences: 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texte d'origine: Les travaux que nous avons engagés ont impliqué la participation de développeurs, d’un modélisateur 3D et multimédia mais aussi d’un ingénieur recherche et développement, révélant de ce fait le caractère R&D de notre projet. Notre participation en 2021 à des activités de veille technologique comme des congrès ou des salons confortent également cette position.\n",
            "Texte traduit en aller-retour: Les travaux que nous avons entrepris ont impliqué la participation de développeurs, d'un modélisateur 3D et multimédia, mais aussi d'un ingénieur en recherche et développement, révélant ainsi le caractère de R-D de notre projet. Notre participation en 2021 à des activités de veille technologique telles que congrès et salons professionnels renforce également cette position.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rétrotraduction sur un fichier .txt"
      ],
      "metadata": {
        "id": "TBP9gqTeVTqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Cette fonction prend un chemin de fichier en entrée et retourne une traduction rétrograde (back-translation) du texte contenu dans le fichier en utilisant deux modèles de traduction automatique de Hugging Face. Le texte d'entrée est d'abord traduit du français vers l'anglais, puis de l'anglais vers le français.\n",
        "\n",
        "  Input :\n",
        "    file_path : str - Le chemin vers le fichier à traduire\n",
        "    src_lang : str - (facultatif) La langue source du texte (français par défaut)\n",
        "    tgt_lang : str - (facultatif) La langue cible pour la traduction (anglais par défaut)\n",
        "\n",
        "  Output :\n",
        "    str - Un message confirmant la création du fichier contenant la traduction rétrograde du texte en entrée.\n",
        "\"\"\"\n",
        "def back_translation_file(file_path, src_lang=\"fr\", tgt_lang=\"en\"):\n",
        "    with open(file_path, \"r\") as fichier:\n",
        "        contenu = fichier.read()\n",
        "    \n",
        "    back_translated_text = back_translation(contenu, src_lang, tgt_lang)\n",
        "    \n",
        "    # Déterminer le nom du fichier de sortie\n",
        "    file_name, file_ext = os.path.splitext(file_path)\n",
        "    file_ext = f\"_back_translated_{tgt_lang}{file_ext}\"\n",
        "    file_out = file_name + file_ext\n",
        "\n",
        "    with open(file_out, \"w\") as output_file:\n",
        "        output_file.write(back_translated_text)\n",
        "\n",
        "    return \"Le fichier \" + file_out + \" a bien été crée.\""
      ],
      "metadata": {
        "id": "dLpaEyrW4d8A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "back_translation_file(\"output.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4F-U_xCS2Aj-",
        "outputId": "33f60b66-fdf6-4906-8a5f-12c93bb60a79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating sentences: 100%|██████████| 76/76 [01:27<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Le fichier output_back_translated_en.txt a bien été crée.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}